{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSVs needed to make the join.\n",
    "ticker = pd.read_csv('data/asx-tickers.csv')\n",
    "headlines = pd.read_csv('data/abcnews-date-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DF into chunks, and process each in a seperate thread on your CPU\n",
    "\n",
    "import numpy as np\n",
    "from multiprocessing import cpu_count, Pool\n",
    "\n",
    "cores = cpu_count()\n",
    " \n",
    "def parallelize(data, func):\n",
    "    data_split = np.array_split(data, cores)\n",
    "    pool = Pool(cores)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to Fuzzy Match up to FIRSTN records\n",
    "\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"HALP\")\n",
    "\n",
    "FIRSTN = 1000\n",
    "\n",
    "# Fuzzy match function\n",
    "def fuzzy_match(x, choices, scorer, cutoff):\n",
    "    return process.extractOne(x, choices=choices, scorer=scorer, score_cutoff=cutoff)\n",
    "    \n",
    "\n",
    "# Parallelization function, to run on each split of data\n",
    "def appfun(df):\n",
    "    return df.loc[:FIRSTN, 'headline_text'].progress_apply(\n",
    "        fuzzy_match,\n",
    "        args=(\n",
    "            ticker.loc[:, 'company'], \n",
    "            fuzz.partial_ratio,\n",
    "            80\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Run in parallel\n",
    "# matching_results = parallelize(headlines, appfun)\n",
    "# test = headlines[:FIRSTN].copy()\n",
    "# test['match'] = matching_results\n",
    "# test[test['match'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nouns = ['NNS', 'NNP', 'NNPS']\n",
    "string = \"qantas urged to update security in shadow of\".split()\n",
    "tags = nltk.tag.pos_tag(string)\n",
    "filtered = \" \".join([x[0] for x in tags if x[1] in nouns])\n",
    "actual = 'QANTAS AIRWAYS LIMITED'.lower()\n",
    "print(filtered, actual)\n",
    "fuzz.ratio(filtered, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attempt to Fuzzy Match only the nouns of a sentence, up to FIRSTN records.\n",
    "\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "tqdm.pandas(desc=\"HALP\")\n",
    "\n",
    "nouns = ['NNS', 'NNP', 'NNPS']\n",
    "\n",
    "FIRSTN = 1000\n",
    "\n",
    "# Fuzzy match function\n",
    "def fuzzy_match(x, choices, scorer, cutoff):\n",
    "    tags = nltk.tag.pos_tag(x.split())\n",
    "    filtered = \" \".join([x[0] for x in tags if x[1] in nouns])\n",
    "    if filtered == '':\n",
    "        return\n",
    "    return process.extractOne(filtered, choices=choices, scorer=scorer, score_cutoff=cutoff)\n",
    "    \n",
    "\n",
    "# Parallelization function, to run on each split of data\n",
    "def appfun(df):\n",
    "    return df.loc[:FIRSTN, 'headline_text'].progress_apply(\n",
    "        fuzzy_match,\n",
    "        args=(\n",
    "            ticker.loc[:, 'company'].map(lambda x: x.lower()), \n",
    "            fuzz.partial_ratio,\n",
    "            65\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Run in parallel\n",
    "matching_results = parallelize(headlines, appfun)\n",
    "test = headlines[:FIRSTN].copy()\n",
    "test['match'] = matching_results\n",
    "test[test['match'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Approach\n",
    "\n",
    "\"\"\"\n",
    "First we want to clean up the company column to make computing percentage of matching \n",
    "characters easier:\n",
    "\n",
    "1. lowercase the entire company column\n",
    "   a. remove punctuation (except spaces).\n",
    "   b. Tokenize on spaces and produce a list of each word vectorized.\n",
    "   \n",
    "Then we want to look at each headline, first cleaning it so it can match the same as\n",
    "the companies would (no punctuation).\n",
    "   \n",
    "2. for each headline:\n",
    "    a. remove punctuation (except spaces).\n",
    "    b. tokenize on spaces and produce a list of each work vectorized.\n",
    "    \n",
    "    \n",
    "    With each cleaned headline, we now have a list of words inside it. For each company we\n",
    "    also have a list of cleaned words. So now we want to try to score each company on how\n",
    "    well its words matches the headline words.\n",
    "    \n",
    "    c. for each company:\n",
    "        i. matchedCompanies = []\n",
    "        \n",
    "        \n",
    "        We do this by under the notion the first word of a company MUST be present. So we\n",
    "        find each word in the headline that starts with the company's first letter. From there\n",
    "        we compare each word starting from this word in the headline to each word in the\n",
    "        company. We do a percentage matching.\n",
    "        \n",
    "        We also want to weigh each successive word less and less, and we want to have a scoring\n",
    "        system where higher is better. This allows headlines like \"quantas under fire for...\"\n",
    "        to score well with companies like \"quantas airlines limited\". If Quantas is found, it should\n",
    "        score super high, yet not allow the mismatch between \"under\" and \"airlines\" to drag it down.\n",
    "        In the event two companies start with the same first word, then the second word matching would\n",
    "        help distinguish.\n",
    "        \n",
    "        \n",
    "        ii. For each word (W) in headline:\n",
    "            1. If it doesn't start with the company's first word first letter, skip\n",
    "            2. CompanyMatchScore = 0\n",
    "            2. for i,C in Company Word List: (where C is the ith word in their name list)\n",
    "            3.   if W+i exists\n",
    "            4.     CompanyMatchScore += percentage_matching(W+i, C) * Weight (the first word should weight far more than latter words)\n",
    "            \n",
    "            \n",
    "            We want to normalize this CompanyMatchScore to be out of 100% when done, as we'll later need\n",
    "            to compare how different company names of different lengths performed. If we don't normalize\n",
    "            then names with more words will score higher than those with less.\n",
    "            \n",
    "            \n",
    "            5. normalizedScore = companyMatchScore / len(CompanyWordList) # Normalizes score out of 100%.\n",
    "            6. matchCompanies.append((company, normalizedScore))\n",
    "            \n",
    "        \n",
    "        Before moving tot the next company, we'll sort the matches to make later filtering easier. We'll\n",
    "        then append these matches into a new column associated with the headlines ('matches'). We can limit\n",
    "        the number of matches to keep to some top N (10? 5?) to prevent filling memory with huge vectors.\n",
    "        \n",
    "        \n",
    "        iii. Sort matchedCompanies by their normalizedScore\n",
    "        iV. df.loc[headlineIndex, 'matches'] = matchedCompanies[:10].\n",
    "\n",
    "\n",
    "Now we have all our matches with their headlines, we can inspect how well it did and start keeping or discarding matches.\n",
    "The thought is that some headlines won't have any companies associated so their match score should be low. We'll drop\n",
    "matches that don't meet a threshold and retain the highest one above the threshold (for those that do meet the threshold).\n",
    "This will leave some false matches behind (for example if \"Bell Labs\" is a company and a headline has \"time to ring the bell\"\n",
    "in it). But once we match enough companies, we can probably keep only those companies who had more than N headlines matched \n",
    "to them for further analysis, allowing us to account for these false positives:\n",
    "        \n",
    "\n",
    "3. Ideally, the correct answer is the first element in each match. \n",
    "    a. If the first match is > some percentage threshold, keep it as the match\n",
    "    b. else the headline had no matches and use NA. \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
