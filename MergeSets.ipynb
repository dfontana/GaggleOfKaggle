{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "# import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSVs needed to make the join.\n",
    "ticker = pd.read_csv('data/asx-tickers.csv')\n",
    "headlines = pd.read_csv('data/abcnews-date-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1AD</td>\n",
       "      <td>ADALTA LIMITED</td>\n",
       "      <td>Pharmaceuticals, Biotechnology &amp; Life Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1AG</td>\n",
       "      <td>ALTERRA LIMITED</td>\n",
       "      <td>Commercial &amp; Professional Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker          company                                        industry\n",
       "0    1AD   ADALTA LIMITED  Pharmaceuticals, Biotechnology & Life Sciences\n",
       "1    1AG  ALTERRA LIMITED              Commercial & Professional Services"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out records that don't have any company word mentions\n",
    "import string\n",
    "translator = str.maketrans('','',string.punctuation)\n",
    "\n",
    "def normalize(s):\n",
    "    return s.lower().translate(translator).split()\n",
    "\n",
    "def incompwords(s):\n",
    "    headwords = set(normalize(s))\n",
    "    return len(headwords & compwords) > 0\n",
    "\n",
    "compwords = set(normalize((\" \".join(ticker['company'].values))))\n",
    "headlines_filtered = headlines[headlines['headline_text'].apply(incompwords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelization Code: Will split data evenly amoungst threads\n",
    "from multiprocessing import cpu_count, Pool\n",
    "\n",
    "cores = cpu_count()\n",
    " \n",
    "def parallelize(data, func):\n",
    "    data_split = np.array_split(data, cores)\n",
    "    pool = Pool(cores)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to Fuzzy Match up to FIRSTN records\n",
    "tqdm.pandas(desc=\"Raw Fuzzy Match\")\n",
    "\n",
    "FIRSTN = 1000\n",
    "\n",
    "# Fuzzy match function\n",
    "def fuzzy_match(x, choices, scorer, cutoff):\n",
    "    return process.extractOne(x, choices=choices, scorer=scorer, score_cutoff=cutoff)\n",
    "    \n",
    "\n",
    "# Parallelization function, to run on each split of data\n",
    "def appfun(df):\n",
    "    return df.loc[:FIRSTN, 'headline_text'].progress_apply(\n",
    "        fuzzy_match,\n",
    "        args=(\n",
    "            ticker.loc[:, 'company'], \n",
    "            fuzz.partial_ratio,\n",
    "            80\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Run in parallel\n",
    "# matching_results = parallelize(headlines, appfun)\n",
    "# test = headlines[:FIRSTN].copy()\n",
    "# test['match'] = matching_results\n",
    "# test[test['match'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nouns = ['NNS', 'NNP', 'NNPS']\n",
    "string = \"qantas urged to update security in shadow of\".split()\n",
    "tags = nltk.tag.pos_tag(string)\n",
    "filtered = \" \".join([x[0] for x in tags if x[1] in nouns])\n",
    "actual = 'QANTAS AIRWAYS LIMITED'.lower()\n",
    "print(filtered, actual)\n",
    "fuzz.ratio(filtered, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attempt to Fuzzy Match only the nouns of a sentence, up to FIRSTN records.\n",
    "from fuzzywuzzy import process, fuzz\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "tqdm.pandas(desc=\"Fuzzy with only Nouns\")\n",
    "\n",
    "nouns = ['NNS', 'NNP', 'NNPS']\n",
    "\n",
    "FIRSTN = 1000\n",
    "\n",
    "# Fuzzy match function\n",
    "def fuzzy_match(x, choices, scorer, cutoff):\n",
    "    tags = nltk.tag.pos_tag(x.split())\n",
    "    filtered = \" \".join([x[0] for x in tags if x[1] in nouns])\n",
    "    if filtered == '':\n",
    "        return\n",
    "    return process.extractOne(filtered, choices=choices, scorer=scorer, score_cutoff=cutoff)\n",
    "    \n",
    "\n",
    "# Parallelization function, to run on each split of data\n",
    "def appfun(df):\n",
    "    return df.loc[:FIRSTN, 'headline_text'].progress_apply(\n",
    "        fuzzy_match,\n",
    "        args=(\n",
    "            ticker.loc[:, 'company'].map(lambda x: x.lower()), \n",
    "            fuzz.partial_ratio,\n",
    "            65\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Run in parallel\n",
    "# matching_results = parallelize(headlines, appfun)\n",
    "# test = headlines[:FIRSTN].copy()\n",
    "# test['match'] = matching_results\n",
    "# test[test['match'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Approach\n",
    "tick_df = ticker.copy();\n",
    "head_df = headlines.copy().head(1000);\n",
    "head_df['matches'] = None\n",
    "head_df.astype({'matches':'object'})\n",
    "\n",
    "print(\"Vectorizing...\")\n",
    "# 1. Vectorize companies and headlines in their stripped form.\n",
    "def vectorize(s):\n",
    "    tokens = normalize(s)\n",
    "    return [ np.array(list(word)) for word in tokens ]\n",
    "tick_df['comp_vec'] = tick_df['company'].apply(vectorize)\n",
    "head_df['head_vec'] = head_df['headline_text'].apply(vectorize)\n",
    "\n",
    "def percentage_matching(W, C):\n",
    "    if len(W) < len(C):\n",
    "        return np.sum(W == C[0:len(W)]) / len(C)\n",
    "    else:\n",
    "        return np.sum(W[0:len(C)] == C) / len(W)\n",
    "\n",
    "# 2. Headline opertion\n",
    "MIN_SCORE = 0.3\n",
    "def findMatches(head_record):\n",
    "    matchedCompanies = []\n",
    "    headWordList = head_record['head_vec']\n",
    "    \n",
    "    for _,comp_record in tick_df.iterrows():\n",
    "        \n",
    "        companyWordList = comp_record['comp_vec']\n",
    "        matchingHeads = []\n",
    "        \n",
    "        \"\"\"\n",
    "        New option: \n",
    "            1. Convert headline and company name to set.\n",
    "            2. Set intersect. \n",
    "            3. For all common words find it's index in the company name\n",
    "            4. Can compute the weighted worth of the match.\n",
    "        \"\"\"\n",
    "        \n",
    "        for wIdx in range(len(headWordList)):\n",
    "            if companyWordList[0][0] != headWordList[wIdx][0]:\n",
    "                continue\n",
    "                          \n",
    "            companyMatchScore = 0\n",
    "            for cIdx,C in enumerate(companyWordList):\n",
    "                if  wIdx+cIdx < len(headWordList):\n",
    "                    weight = 1/(cIdx+1)\n",
    "                    W = headWordList[wIdx+cIdx]\n",
    "                    matches = percentage_matching(W, C)\n",
    "                    if matches == 1.0:\n",
    "                        companyMatchScore += (matches * weight)\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            normalizedScore = companyMatchScore / len(companyWordList) # Normalizes score out of 100%.\n",
    "            if normalizedScore >= MIN_SCORE:\n",
    "                matchedCompanies.append((comp_record['company'], normalizedScore))\n",
    "                \n",
    "    matchedCompanies.sort(key=lambda x: x[1], reverse=True)\n",
    "    return matchedCompanies[:10]\n",
    "\n",
    "# Uncomment for parallel and comment the bottom part\n",
    "# tqdm.pandas(desc=\"HALP\")\n",
    "# def appfun(df):\n",
    "#     print('GO')\n",
    "#     return df.progress_apply(findMatches, axis=1)\n",
    "\n",
    "# print(\"Looping...\")\n",
    "# parallelize(head_df, appfun)\n",
    "\n",
    "# tqdm_notebook().pandas(\"matching\")\n",
    "# head_df['matches'] = head_df.progress_apply(findMatches, axis=1)\n",
    "# head_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "\n",
      "Looping...\n",
      "GO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HALP:   0%|          | 29/187597 [00:10<20:55:13,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HALP:   0%|          | 7/187596 [00:02<21:44:08,  2.40it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HALP:   0%|          | 37/187596 [00:14<18:08:28,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HALP:   0%|          | 40/187596 [00:15<17:13:04,  3.03it/s]"
     ]
    }
   ],
   "source": [
    "## Set Union Approach for faster computation.\n",
    "tick_df = ticker.copy();\n",
    "head_df = headlines_filtered.copy();\n",
    "head_df['matches'] = None\n",
    "head_df.astype({'matches':'object'})\n",
    "\n",
    "print(\"Vectorizing...\")\n",
    "# 1. Vectorize companies and headlines in their stripped form.\n",
    "tick_df['comp_set'] = tick_df['company'].apply(lambda x: set(normalize(x)))\n",
    "head_df['head_set'] = head_df['headline_text'].apply(lambda x: set(normalize(x)))\n",
    "tick_df['comp_list'] = tick_df['company'].apply(lambda x: normalize(x))\n",
    "head_df['head_list'] = head_df['headline_text'].apply(lambda x: normalize(x))\n",
    "\n",
    "# 2. Headline opertion\n",
    "MIN_SCORE = 0.3\n",
    "def findMatches(head_record):\n",
    "    matchedCompanies = []\n",
    "    headWordList = head_record['head_set']\n",
    "    \n",
    "    for _,comp_record in tick_df.iterrows():\n",
    "        \n",
    "        companyWordList = comp_record['comp_set']\n",
    "        matchingHeads = []\n",
    "        \n",
    "        \"\"\"\n",
    "        New option: \n",
    "            1. Convert headline and company name to set.\n",
    "            2. Set intersect. \n",
    "            3. For all common words find it's index in the company name\n",
    "            4. Can compute the weighted worth of the match.\n",
    "        \"\"\"\n",
    "        \n",
    "        companyMatchScore = 0\n",
    "        shared = headWordList & companyWordList\n",
    "        if len(shared) > 0:\n",
    "            for word in shared:\n",
    "                idx = comp_record['comp_list'].index(word)\n",
    "                companyMatchScore += (1/(idx+1))\n",
    "        normalizedScore = companyMatchScore / len(companyWordList)\n",
    "        if normalizedScore >= MIN_SCORE:\n",
    "            matchedCompanies.append((comp_record['company'], normalizedScore))\n",
    "            \n",
    "                \n",
    "    matchedCompanies.sort(key=lambda x: x[1], reverse=True)\n",
    "    return matchedCompanies[:10]\n",
    "\n",
    "# Uncomment for parallel and comment the bottom part\n",
    "tqdm.pandas(desc=\"HALP\")\n",
    "def appfun(df):\n",
    "    print('GO')\n",
    "    return df.progress_apply(findMatches, axis=1)\n",
    "\n",
    "print(\"Looping...\")\n",
    "parallelize(head_df, appfun)\n",
    "\n",
    "# tqdm_notebook().pandas(\"matching\")\n",
    "# head_df['matches'] = head_df.progress_apply(findMatches, axis=1)\n",
    "# head_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Approach\n",
    "\n",
    "\"\"\"\n",
    "First we want to clean up the company column to make computing percentage of matching \n",
    "characters easier:\n",
    "\n",
    "1. lowercase the entire company column\n",
    "   a. remove punctuation (except spaces).\n",
    "   b. Tokenize on spaces and produce a list of each word vectorized.\n",
    "   \n",
    "Then we want to look at each headline, first cleaning it so it can match the same as\n",
    "the companies would (no punctuation).\n",
    "   \n",
    "2. for each headline:\n",
    "    a. remove punctuation (except spaces).\n",
    "    b. tokenize on spaces and produce a list of each work vectorized.\n",
    "    \n",
    "    \n",
    "    With each cleaned headline, we now have a list of words inside it. For each company we\n",
    "    also have a list of cleaned words. So now we want to try to score each company on how\n",
    "    well its words matches the headline words.\n",
    "    \n",
    "    c. for each company:\n",
    "        i. matchedCompanies = []\n",
    "        \n",
    "        \n",
    "        We do this by under the notion the first word of a company MUST be present. So we\n",
    "        find each word in the headline that starts with the company's first letter. From there\n",
    "        we compare each word starting from this word in the headline to each word in the\n",
    "        company. We do a percentage matching.\n",
    "        \n",
    "        We also want to weigh each successive word less and less, and we want to have a scoring\n",
    "        system where higher is better. This allows headlines like \"quantas under fire for...\"\n",
    "        to score well with companies like \"quantas airlines limited\". If Quantas is found, it should\n",
    "        score super high, yet not allow the mismatch between \"under\" and \"airlines\" to drag it down.\n",
    "        In the event two companies start with the same first word, then the second word matching would\n",
    "        help distinguish.\n",
    "        \n",
    "        \n",
    "        ii. For each word (W) in headline:\n",
    "            1. If it doesn't start with the company's first word first letter, skip\n",
    "            2. CompanyMatchScore = 0\n",
    "            2. for i,C in Company Word List: (where C is the ith word in their name list)\n",
    "            3.   if W+i exists\n",
    "            4.     CompanyMatchScore += percentage_matching(W+i, C) * Weight (the first word should weight far more than latter words)\n",
    "            \n",
    "            \n",
    "            We want to normalize this CompanyMatchScore to be out of 100% when done, as we'll later need\n",
    "            to compare how different company names of different lengths performed. If we don't normalize\n",
    "            then names with more words will score higher than those with less.\n",
    "            \n",
    "            \n",
    "            5. normalizedScore = companyMatchScore / len(CompanyWordList) # Normalizes score out of 100%.\n",
    "            6. matchCompanies.append((company, normalizedScore))\n",
    "            \n",
    "        \n",
    "        Before moving tot the next company, we'll sort the matches to make later filtering easier. We'll\n",
    "        then append these matches into a new column associated with the headlines ('matches'). We can limit\n",
    "        the number of matches to keep to some top N (10? 5?) to prevent filling memory with huge vectors.\n",
    "        \n",
    "        \n",
    "        iii. Sort matchedCompanies by their normalizedScore\n",
    "        iV. df.loc[headlineIndex, 'matches'] = matchedCompanies[:10].\n",
    "\n",
    "\n",
    "Now we have all our matches with their headlines, we can inspect how well it did and start keeping or discarding matches.\n",
    "The thought is that some headlines won't have any companies associated so their match score should be low. We'll drop\n",
    "matches that don't meet a threshold and retain the highest one above the threshold (for those that do meet the threshold).\n",
    "This will leave some false matches behind (for example if \"Bell Labs\" is a company and a headline has \"time to ring the bell\"\n",
    "in it). But once we match enough companies, we can probably keep only those companies who had more than N headlines matched \n",
    "to them for further analysis, allowing us to account for these false positives:\n",
    "        \n",
    "\n",
    "3. Ideally, the correct answer is the first element in each match. \n",
    "    a. If the first match is > some percentage threshold, keep it as the match\n",
    "    b. else the headline had no matches and use NA. \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
